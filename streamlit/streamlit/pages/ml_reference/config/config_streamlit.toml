[datasets] # ADNEX Dataset
[datasets.Offline_Revenue]
name = "Retail Total Revenue"
sql = """
    SELECT
        DATE(created_at) AS date,
        order_source_name AS store_name,
        SUM(items_total_dollar_after_discount) AS total_revenue
    FROM `nongchunxiang-ga4.prod_mart.mart-orders_details`
    WHERE order_source_type = 'offline_store'
        AND order_status = 'completed'
        AND DATE(created_at) >= '2022-01-01'
        AND items_total_dollar_after_discount > 0
        AND items_total_dollar_after_discount < 12000
    GROUP BY store_name, date
    ORDER BY store_name, date
"""
date = "date"
[datasets.Offline_Revenue.target]
target1 = "total_revenue"
[datasets.Item_Sale_Quantity]
name = "Retail Item Sale Quantity"
sql = """
WITH UniqueItems2024 AS (
    SELECT DISTINCT
        item_category,
        product_name AS item_name
    FROM `nongchunxiang-ga4.prod_mart.mart-products_list`
    WHERE product_retail_status = "active"
    ORDER BY item_category, item_name
)

SELECT 
    DATE(d.created_at) AS date,
    d.order_source_name AS store_name,
    d.item_category,
    d.item_name,
    SUM(d.quantity) AS total_quantity
FROM `nongchunxiang-ga4.prod_mart.mart-orders_details` d
JOIN UniqueItems2024 u
    ON d.item_category = u.item_category AND d.item_name = u.item_name
WHERE d.order_source_type = 'offline_store'
    AND d.order_status = 'completed'
    AND DATE(d.created_at) >= '2022-01-01'
GROUP BY store_name, d.item_category, d.item_name, date
ORDER BY store_name, date
    """
date = "date"
[datasets.Item_Sale_Quantity.target]
target1 = "total_quantity"
[datasets.Online_Revenue]
name = "Online Total Revenue"
sql = """
    SELECT
        DATE(created_at) AS date,
        SUM(items_total_dollar_after_discount) AS total_revenue
    FROM `nongchunxiang-ga4.prod_mart.mart-orders_details`
    WHERE order_source_type != 'offline_store'
        AND order_source_type != 'offline_store_other'
        AND order_status = 'completed'
    GROUP BY date
    ORDER BY date
    """
date = "date"
[datasets.Online_Revenue.target]
target1 = "total_revenue"




[columns]
date = false # Name of date column, choose false to select it directly in the app.
target = false # Name of target column, choose false to select it directly in the app.
dimensions = false # List of dimension columns, choose false to select it directly in the app.
regressors = false # List of regressor columns, choose false to select it directly in the app.

[dataprep] # Default dataprep parameters
date_format = "%Y-%m-%d"
dimensions_agg = ["Sum", "Mean", "Min", "Max"] # List of possible target agg functions over dimensions. First is the default option.
remove_days = [] # List of days of week to remove from dataset.
# Select up to 6 elements among "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday".
remove_zeros = false # Whether or not to remove rows where target is 0 (true or false).
remove_negative = false # Whether or not to remove rows where target is <0 (true or false).
log_transform = false # Whether or not to apply a target log transform (true or false).

[model] # Default model parameters
seasonality_prior_scale = 10
holidays_prior_scale = 10
regressors_prior_scale = 10
changepoint_prior_scale = 0.05
growth = ['linear', 'logistic', 'flat'] # List of options, the first element of the list will be the default parameter.
cap = 5.0 # Cap value in case logistic growth is selected
floor = 0.0 # Floor value in case logistic growth is selected
seasonality_mode = ['additive', 'multiplicative'] # List of options, the first element of the list will be the default parameter.
changepoint_range = 0.8
holidays_country = "TW" # List of countries whose holidays will be added as regressors.
# Options: "FR", "US", "UK", "CA", "BR", "MX", "IN", "CN", "JP", "DE", "IT", "RU", "BE", "PT", "PL"
public_holidays = true
school_holidays = false
lockdown_events = []  # list of int with lockdown number (starting at 0) for the selected country

[horizon]
s = 86400 # Default number of seconds in validation set if dataset frequency is in seconds
H = 96 # Default number of hours in validation set if dataset frequency is in hours
D = 30 # Default number of days in validation set if dataset frequency is in days
W = 10 # Default number of weeks in validation set if dataset frequency is in weeks
M = 6 # Default number of months in validation set if dataset frequency is in months
Q = 4 # Default number of quarters in validation set if dataset frequency is in quarters
Y = 3 # Default number of years in validation set if dataset frequency is in years

[split]
CV = 5 # Default number of cross-validation folds if cross-validation is selected
gap_train_valid = 1 # Default number of days between training set and validation set

[validity]
min_data_points_train = 30 # Minimum number of datapoints (-1) to have in training set to train a model
min_data_points_val = 1 # Minimum number of datapoints (-1) to have in validation set to evaluate model
min_target_cardinality = 5 # Minimum number of distinct values that the target should have
max_cat_reg_cardinality = 5 # Maximum number of distinct values that a categorical regressor should have

[metrics]
[metrics.default] # List of metrics to display by default (among "MAPE", "RMSE", "SMAPE", "MAE", "MSE")
selection = ["MAPE", "RMSE", "SMAPE", "MAE"]
[metrics.digits] # Number of decimals to use when displaying metrics
MAPE = 4
SMAPE = 4
MSE = 1
RMSE = 2
MAE = 2

[style]
colors = ["#002244", "#ff0066", "#66cccc", "#ff9933", "#337788",
          "#429e79", "#474747", "#f7d126", "#ee5eab", "#b8b8b8"] # Color palette for visualizations
color_axis = '#d62728' # Color for axis on residuals chart and scatter plot
waterfall_digits = 2 # Number of digits in waterfall chart

[global]
seed = 42 # Random seed for modelling
