import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve
import plotly.figure_factory as ff
import plotly.graph_objects as go
import time
from tqdm import tqdm
from pygwalker.api.streamlit import StreamlitRenderer
import xgboost as xgb
import lightgbm as lgb
import shap
from openai import OpenAI

st.set_page_config(page_title="@data_lemak", layout="wide")
st.sidebar.title("è¨­ç½®")

with st.sidebar.expander("OpenAI API Settings"):
    openai_apikey = st.text_input("Enter OpenAI API Key", type="password")
    if openai_apikey:
        st.success("API Key entered!")
        client = OpenAI(api_key=openai_apikey)
    temperature = st.slider("Temperature", min_value=0.0, max_value=1.0, value=0.7, step=0.1)
    openai_model = st.selectbox("OpenAI Model", ["gpt-3.5-turbo", "gpt-4", "gpt-4o"])

    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = openai_model
    else:
        st.session_state["openai_model"] = openai_model

if "messages" not in st.session_state:
    st.session_state.messages = []

st.sidebar.divider()
st.sidebar.header("å°ˆæ¡ˆæµç¨‹")
sidebar_options = [
    "1. åŠ è¼‰æ•¸æ“š",
    "2. æ•¸æ“šæ¢ç´¢å’Œå¯è¦–åŒ–",
    "3. æ•¸æ“šé è™•ç†",
    "4. ç‰¹å¾µå·¥ç¨‹",
    "5. æ¨¡å‹é¸æ“‡èˆ‡è¨“ç·´",
    "6. æ¨¡å‹è©•ä¼°",
    "7. æ¨¡å‹éƒ¨ç½²æ¨¡æ“¬",
    "8. What-If åˆ†æ"
]
selected_option = st.sidebar.radio("é¸æ“‡æ­¥é©Ÿ(Demo)", sidebar_options)
st.title("ğŸ“Š ç”¨æˆ¶æµå¤±é æ¸¬èˆ‡AI-Chatbot")

tab1, tab2 = st.tabs([ "ç”¨æˆ¶æµå¤±ç‡é æ¸¬ç³»çµ±","Chatbot"])
with tab2:
    st.header("Chatbot")

    # å‰µå»ºä¸€å€‹å®¹å™¨ä¾†åŒ…å«æ•´å€‹èŠå¤©æ©Ÿå™¨äºº
    chat_container = st.container()
    
    with chat_container:
        # é¡¯ç¤ºèŠå¤©æ­·å²
        
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # å¹³æ»‘æ»¾å‹•åˆ°èŠå¤©æœ«å°¾
        st.markdown("<div id='end-of-chat'></div>", unsafe_allow_html=True)
        st.markdown("""
        <script>
        const endOfChat = document.querySelector('#end-of-chat');
        if (endOfChat) {
            endOfChat.scrollIntoView({ behavior: 'smooth' });
        }
        </script>
        """, unsafe_allow_html=True)
        if openai_apikey:
            if prompt := st.chat_input("You:"):
                if openai_apikey == '1': 
                    st.warning("Warning: Please do not share personal information.")
                else:
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    with st.chat_message("user"):
                        st.markdown(prompt)
                    with st.chat_message("assistant"):
                        message_placeholder = st.empty()
                        full_response = ""
                        try:
                            response = client.chat.completions.create(
                                model=st.session_state["openai_model"],
                                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                                temperature=temperature
                            )
                            full_response = response.choices[0].message.content
                            message_placeholder.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        except Exception as e:
                            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                            full_response = "å¾ˆæŠ±æ­‰ï¼Œç”Ÿæˆå›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è«‹æª¢æŸ¥æ‚¨çš„APIå¯†é‘°å’Œç¶²çµ¡é€£æ¥ï¼Œç„¶å¾Œé‡è©¦ã€‚"
                            message_placeholder.markdown(full_response)
                    st.rerun()

        if st.button('æ¸…é™¤å°è©±'):
            st.session_state.messages = []
            st.rerun()




with tab1:
    st.title("ç”¨æˆ¶æµå¤±ç‡é æ¸¬ç³»çµ±")
    st.header("1. Data Loading")
    data_option = st.radio("é¸æ“‡æ•¸æ“šä¾†æº", ["ä¸Šå‚³CSVæ–‡ä»¶", "éš¨æ©Ÿè³‡æ–™"])

    def load_sample_data(n_samples=1000):
        np.random.seed(42)
        df = pd.DataFrame({
            'age': np.random.randint(18, 80, n_samples),
            'tenure': np.random.randint(0, 60, n_samples),
            'balance': np.random.uniform(0, 250000, n_samples),
            'num_products': np.random.randint(1, 5, n_samples),
            'has_credit_card': np.random.choice([0, 1], n_samples),
            'is_active_member': np.random.choice([0, 1], n_samples),
            'estimated_salary': np.random.uniform(30000, 200000, n_samples),
            'churn': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])
        })
        return df

    if data_option == "ä¸Šå‚³CSVæ–‡ä»¶":
        uploaded_file = st.file_uploader("ä¸Šå‚³CSVæ–‡ä»¶", type="csv")
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            st.success("æˆåŠŸè¼‰å…¥ä¸Šå‚³çš„CSVæ–‡ä»¶ï¼")
            st.session_state.df = df
        else:
            st.warning("Please upload a CSV file @data_lemak")
            st.stop()
    else:
        n_samples = st.number_input("è¨­å®šæ¨£æœ¬æ•¸", min_value=1000, value=1000, step=50)
        df = load_sample_data(n_samples)
        st.success("Successfully Loaded Dataset! @data_lemak")
        st.session_state.df = df

    st.write(st.session_state.df.head())


    st.header("2. Data Exploration and Visualization")
    with st.expander("å±•é–‹ä»¥æŸ¥çœ‹æ•¸æ“šæ¢ç´¢"):
        st.write("ä½¿ç”¨ PyGWalker é€²è¡Œæ•¸æ“šæ¢ç´¢:")

        if 'df' in st.session_state:
            vis_spec = r"""{"config":[{"config":{"defaultAggregated":true,"geoms":["auto"],"coordSystem":"generic","limit":-1,"timezoneDisplayOffset":0,"folds":["tenure"]},"encodings":{"dimensions":[{"fid":"num_products","name":"num_products","basename":"num_products","semanticType":"quantitative","analyticType":"dimension","offset":0},{"fid":"churn","name":"churn","basename":"churn","semanticType":"quantitative","analyticType":"dimension","offset":0},{"fid":"age","name":"age","basename":"age","analyticType":"dimension","semanticType":"quantitative","aggName":"sum","offset":0},{"fid":"has_credit_card","name":"has_credit_card","basename":"has_credit_card","semanticType":"quantitative","analyticType":"dimension","offset":0},{"fid":"is_active_member","name":"is_active_member","basename":"is_active_member","semanticType":"quantitative","analyticType":"dimension","offset":0},{"fid":"gw_mea_key_fid","name":"Measure names","analyticType":"dimension","semanticType":"nominal"}],"measures":[{"fid":"tenure","name":"tenure","basename":"tenure","analyticType":"measure","semanticType":"quantitative","aggName":"sum","offset":0},{"fid":"balance","name":"balance","basename":"balance","analyticType":"measure","semanticType":"quantitative","aggName":"sum","offset":0},{"fid":"estimated_salary","name":"estimated_salary","basename":"estimated_salary","analyticType":"measure","semanticType":"quantitative","aggName":"sum","offset":0},{"fid":"gw_count_fid","name":"Row count","analyticType":"measure","semanticType":"quantitative","aggName":"sum","computed":true,"expression":{"op":"one","params":[],"as":"gw_count_fid"}},{"fid":"gw_mea_val_fid","name":"Measure values","analyticType":"measure","semanticType":"quantitative","aggName":"sum"}],"rows":[{"fid":"gw_count_fid","name":"Row count","analyticType":"measure","semanticType":"quantitative","aggName":"sum","computed":true,"expression":{"op":"one","params":[],"as":"gw_count_fid"}}],"columns":[{"fid":"age","name":"age","basename":"age","analyticType":"dimension","semanticType":"quantitative","aggName":"sum","offset":0}],"color":[],"opacity":[],"size":[],"shape":[],"radius":[],"theta":[],"longitude":[],"latitude":[],"geoId":[],"details":[{"fid":"tenure","name":"tenure","basename":"tenure","analyticType":"measure","semanticType":"quantitative","aggName":"mean","offset":0},{"fid":"estimated_salary","name":"estimated_salary","basename":"estimated_salary","analyticType":"measure","semanticType":"quantitative","aggName":"mean","offset":0}],"filters":[],"text":[]},"layout":{"showActions":false,"showTableSummary":false,"stack":"stack","interactiveScale":false,"zeroScale":true,"size":{"mode":"full","width":320,"height":200},"format":{},"geoKey":"name","resolve":{"x":false,"y":false,"color":false,"opacity":false,"shape":false,"size":false}},"visId":"gw_fRWT","name":"Chart 1"}],"chart_map":{},"workflow_list":[{"workflow":[{"type":"transform","transform":[{"key":"gw_count_fid","expression":{"op":"one","params":[],"as":"gw_count_fid"}}]},{"type":"view","query":[{"op":"aggregate","groupBy":["age"],"measures":[{"field":"gw_count_fid","agg":"sum","asFieldKey":"gw_count_fid_sum"},{"field":"tenure","agg":"mean","asFieldKey":"tenure_mean"},{"field":"estimated_salary","agg":"mean","asFieldKey":"estimated_salary_mean"}]}]}]}],"version":"0.4.9.7"}"""
            pyg_app = StreamlitRenderer(df, vis_spec=vis_spec)
            pyg_app.explorer()
        else:
            st.warning("Please load the data first! @data_lemak")


    st.header("3. Data Preprocessing")
    with st.expander("å±•é–‹ä»¥æŸ¥çœ‹æ•¸æ“šé è™•ç†"):
        st.write("Missing Value Imputation")
        fill_methods = {col: st.selectbox(f"é¸æ“‡ {col} çš„å¡«è£œæ–¹å¼", ['mean', 'mode', '0'], key=f"fill_{col}") for col in st.session_state.df.columns}

        if st.button("åŸ·è¡Œæ•¸æ“šé è™•ç†"):
            progress_text = st.empty()
            progress_bar = st.progress(0)
            for i, column in tqdm(enumerate(st.session_state.df.columns), desc="åŸ·è¡Œæ•¸æ“šé è™•ç†", total=len(st.session_state.df.columns), ncols=100, bar_format="{l_bar}{bar} [æ™‚é–“å‰©é¤˜: {remaining}]"):
                progress_text.text(f"æ­£åœ¨è™•ç†: {column}")
                if st.session_state.df[column].dtype != 'object':
                    if fill_methods[column] == 'mean':
                        st.session_state.df[column] = st.session_state.df[column].fillna(st.session_state.df[column].mean())
                    elif fill_methods[column] == 'mode':
                        st.session_state.df[column] = st.session_state.df[column].fillna(st.session_state.df[column].mode()[0])
                    else:
                        st.session_state.df[column] = st.session_state.df[column].fillna(0)
                else:
                    st.session_state.df[column] = st.session_state.df[column].fillna(st.session_state.df[column].mode()[0])
                progress_bar.progress((i + 1) / len(st.session_state.df.columns))
                time.sleep(0.1)  
            progress_text.text("æ•¸æ“šé è™•ç†å®Œæˆï¼")
            st.success("Data preprocessing completed! @data_lemak")
            st.write(st.session_state.df.head())

    # Feature Engineering
    st.header("4. Feature Engineering")
    with st.expander("å±•é–‹ä»¥æŸ¥çœ‹ç‰¹å¾µå·¥ç¨‹"):
        features_to_process = ['age', 'tenure', 'balance', 'num_products', 'has_credit_card', 'is_active_member', 'estimated_salary']

        feature_bins = {}
        for feature in features_to_process:
            if st.session_state.df[feature].dtype != 'object':
                st.subheader(f"{feature} åˆ†çµ„è¨­ç½®")
                num_bins = st.slider(f"Number of bins for {feature}", 2, 10, 4, key=f"bins_{feature}")
                min_val, max_val = float(st.session_state.df[feature].min()), float(st.session_state.df[feature].max())
                bins = st.slider(f"Bin range for {feature}", min_val, max_val, (min_val, max_val), key=f"range_{feature}")
                feature_bins[feature] = np.linspace(bins[0], bins[1], num_bins + 1)

        def process_feature(feature, feature_name):
            if feature_name in ['has_credit_card', 'is_active_member']:
                return feature.map({0: 'No', 1: 'Yes'})
            elif feature_name in feature_bins:
                return pd.cut(feature, bins=feature_bins[feature_name], labels=[f'bin_{i+1}' for i in range(len(feature_bins[feature_name])-1)])
            else:
                return feature

        if st.button("åŸ·è¡Œç‰¹å¾µå·¥ç¨‹"):
            progress_text = st.empty()
            progress_bar = st.progress(0)
            for i, feature in tqdm(enumerate(features_to_process), desc="åŸ·è¡Œç‰¹å¾µå·¥ç¨‹", total=len(features_to_process), ncols=100, bar_format="{l_bar}{bar} [æ™‚é–“å‰©é¤˜: {remaining}]"):
                progress_text.text(f"æ­£åœ¨è™•ç†: {feature}")
                st.session_state.df[feature + '_processed'] = process_feature(st.session_state.df[feature], feature)
                progress_bar.progress((i + 1) / len(features_to_process))
                time.sleep(0.1)
            progress_text.text("ç‰¹å¾µå·¥ç¨‹å®Œæˆï¼")
            st.success("Feature engineering completed! @data_lemak")
            st.write(st.session_state.df.head())

    # Select features
    st.header("5. Select Features for Training")
    features_for_model = st.multiselect(
        "é¸æ“‡ç‰¹å¾µ",
        options=[col for col in st.session_state.df.columns if col.endswith('_processed') or col in features_to_process],
        default=[col for col in st.session_state.df.columns if col.endswith('_processed') or col in features_to_process]
    )

    # Model Selection and Training
    st.header("6. Model Selection and Training")
    tuning_method = st.radio("é¸æ“‡è¶…åƒæ•¸èª¿å„ªæ–¹æ³•", ["æ‰‹å‹•èª¿æ•´", "GridSearchCV", "RandomizedSearchCV"])
    if tuning_method == "æ‰‹å‹•èª¿æ•´":
        n_splits = st.slider("K-Fold äº¤å‰é©—è­‰æŠ˜æ•¸", 2, 10, 5)
    model_option = st.selectbox("é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹", ["Random Forest", "XGBoost", "LightGBM"])


    def get_model_params(model_option):
        if model_option == "Random Forest":
            return {
                'n_estimators': st.slider("æ¨¹çš„æ•¸é‡", 10, 1000, 100),
                'max_depth': st.slider("æœ€å¤§æ·±åº¦", 1, 50, 10),
                'min_samples_split': st.slider("æœ€å°åˆ†è£‚æ¨£æœ¬æ•¸", 2, 20, 2),
                'min_samples_leaf': st.slider("æœ€å°è‘‰å­æ¨£æœ¬æ•¸", 1, 20, 1),
                'max_features': st.selectbox("æœ€å¤§ç‰¹å¾µæ•¸", ["sqrt", "log2", None])
            }
        elif model_option == "XGBoost":
            return {
                'n_estimators': st.slider("æ¨¹çš„æ•¸é‡", 10, 1000, 100),
                'learning_rate': st.slider("å­¸ç¿’ç‡", 0.01, 1.0, 0.1),
                'max_depth': st.slider("æœ€å¤§æ·±åº¦", 1, 20, 6),
                'min_child_weight': st.slider("æœ€å°å­æ¬Šé‡", 1, 10, 1),
                'gamma': st.slider("ä¿®å‰ªé–¾å€¼", 0.0, 1.0, 0.0, 0.1),
                'subsample': st.slider("å­æ¡æ¨£æ¯”ä¾‹", 0.1, 1.0, 1.0, 0.1),
                'colsample_bytree': st.slider("ç‰¹å¾µæ¡æ¨£æ¯”ä¾‹", 0.1, 1.0, 1.0, 0.1)
            }
        else:  # LightGBM
            return {
                'n_estimators': st.slider("æ¨¹çš„æ•¸é‡", 10, 1000, 100),
                'learning_rate': st.slider("å­¸ç¿’ç‡", 0.01, 1.0, 0.1),
                'num_leaves': st.slider("è‘‰å­æ•¸é‡", 20, 3000, 31),
                'max_depth': st.slider("æœ€å¤§æ·±åº¦", -1, 20, -1),
                'min_child_samples': st.slider("æœ€å°å­æ¨£æœ¬æ•¸", 1, 100, 20),
                'subsample': st.slider("å­æ¡æ¨£æ¯”ä¾‹", 0.1, 1.0, 1.0, 0.1),
                'colsample_bytree': st.slider("ç‰¹å¾µæ¡æ¨£æ¯”ä¾‹", 0.1, 1.0, 1.0, 0.1)
            }

    def get_model(model_option, model_params):
        if model_option == "Random Forest":
            return RandomForestClassifier(**model_params, random_state=42, n_jobs=-1)
        elif model_option == "XGBoost":
            return xgb.XGBClassifier(**model_params, random_state=42, n_jobs=-1)
        else:  # LightGBM
            return lgb.LGBMClassifier(**model_params, random_state=42, n_jobs=-1)

    if tuning_method == "æ‰‹å‹•èª¿æ•´":
        model_params = get_model_params(model_option)
        model = get_model(model_option, model_params)

        if st.button("è¨“ç·´æ¨¡å‹"):
            X = st.session_state.df[features_for_model]
            y = st.session_state.df['churn']
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            progress_bar = st.progress(0)
            progress_text = st.empty()
            cv_scores = []
            kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

            with tqdm(total=n_splits, desc="ç¸½é«”é€²åº¦") as pbar_outer:
                for fold, (train_index, val_index) in enumerate(kf.split(X_train_scaled)):
                    X_train_cv, X_val_cv = X_train_scaled[train_index], X_train_scaled[val_index]
                    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]
                    with tqdm(total=100, desc=f"Fold {fold+1}/{n_splits}", leave=False) as pbar_inner:
                        for i in range(10):  # æ¨¡æ“¬è¨“ç·´éç¨‹
                            model.fit(X_train_cv, y_train_cv)
                            pbar_inner.update(10)
                            time.sleep(0.01)  # æ¨¡æ“¬è¨“ç·´æ™‚é–“
                    score = model.score(X_val_cv, y_val_cv)
                    cv_scores.append(score)
                    pbar_outer.update(1)
                    progress = (fold + 1) / n_splits
                    progress_bar.progress(progress)
                    progress_text.text(f"ç¸½é«”é€²åº¦: {progress*100:.0f}% (Fold {fold+1}/{n_splits})")

            mean_cv_score = np.mean(cv_scores)
            with tqdm(total=100, desc="æœ€çµ‚æ¨¡å‹è¨“ç·´") as pbar_final:
                for i in range(10):  # æ¨¡æ“¬æœ€çµ‚è¨“ç·´éç¨‹
                    model.fit(X_train_scaled, y_train)
                    pbar_final.update(10)
                    time.sleep(0.01)  # æ¨¡æ“¬è¨“ç·´æ™‚é–“

            y_pred = model.predict(X_test_scaled)
            y_prob = model.predict_proba(X_test_scaled)[:, 1]

            st.session_state.update({
                'model': model,
                'X_test': X_test,
                'X_test_scaled': X_test_scaled,
                'y_test': y_test,
                'y_pred': y_pred,
                'y_prob': y_prob,
                'scaler': scaler,
                'features': X.columns,
                'cv_scores': cv_scores
            })

            st.success("Model training completed! You can proceed with model evaluation and interpretation. @data_lemak")

    elif tuning_method in ["GridSearchCV", "RandomizedSearchCV"]:
        param_grid = {
            'Random Forest': {
                'n_estimators': [100, 200, 300],
                'max_depth': [10, 20, 30],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4],
                'max_features': ['sqrt', 'log2']
            },
            'XGBoost': {
                'n_estimators': [100, 200, 300],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [6, 10, 15],
                'min_child_weight': [1, 3, 5],
                'gamma': [0, 0.1, 0.2],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0]
            },
            'LightGBM': {
                'n_estimators': [100, 200, 300],
                'learning_rate': [0.01, 0.1, 0.2],
                'num_leaves': [31, 50, 100],
                'max_depth': [-1, 10, 20],
                'min_child_samples': [20, 30, 40],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0]
            }
        }

        model_params = get_model_params(model_option)
        model = get_model(model_option, model_params)
        search_method = GridSearchCV if tuning_method == "GridSearchCV" else RandomizedSearchCV
        search = search_method(model, param_grid[model_option], cv=3, n_jobs=-1)

        if st.button("è¨“ç·´æ¨¡å‹"):
            X = st.session_state.df[features_for_model]
            y = st.session_state.df['churn']
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            progress_bar = st.progress(0)
            progress_text = st.empty()

            n_iter = 10  # æ¨¡æ“¬æœç´¢éç¨‹çš„è¿­ä»£æ¬¡æ•¸
            with tqdm(total=n_iter, desc="è¶…åƒæ•¸æœç´¢é€²åº¦") as pbar_search:
                for i in range(n_iter):
                    search.fit(X_train_scaled, y_train)
                    progress = (i + 1) / n_iter
                    progress_bar.progress(progress)
                    progress_text.text(f"è¶…åƒæ•¸æœç´¢é€²åº¦: {progress*100:.0f}% @data_lemak")
                    pbar_search.update(1)
                    time.sleep(0.1)  # æ¨¡æ“¬æœç´¢æ™‚é–“

            best_model = search.best_estimator_

            y_pred = best_model.predict(X_test_scaled)
            y_prob = best_model.predict_proba(X_test_scaled)[:, 1]

            st.session_state.update({
                'model': best_model,
                'X_test': X_test,
                'X_test_scaled': X_test_scaled,
                'y_test': y_test,
                'y_pred': y_pred,
                'y_prob': y_prob,
                'scaler': scaler,
                'features': X.columns,
                'cv_scores': []  # Clear cv_scores to avoid errors
            })

            st.success("Model training completed! You can proceed with model evaluation and interpretation. @data_lemak")

    # Model Evaluation
    st.header("7. Model Evaluation")

    if 'model' in st.session_state:
        if tuning_method == "æ‰‹å‹•èª¿æ•´":
            st.subheader("äº¤å‰é©—è­‰çµæœ")
            cv_scores = st.session_state.get('cv_scores', [])
            if cv_scores:
                col1, col2 = st.columns(2)
                col1.metric("äº¤å‰é©—è­‰å¹³å‡å¾—åˆ†:", f"{np.mean(cv_scores):.4f}")
                col2.metric("æ¨™æº–å·®", f"{np.std(cv_scores):.4f}")

                color_option = st.selectbox("é¸æ“‡åœ–è¡¨é¡è‰²", ["lightblue", "lightgreen", "lightcoral", "plum", "peachpuff"])
                color_map = {
                    "lightblue": "#ADD8E6",
                    "lightgreen": "#90EE90",
                    "lightcoral": "#F08080",
                    "plum": "#DDA0DD",
                    "peachpuff": "#FFDAB9"
                }
                selected_color = color_map[color_option]
                fig = go.Figure(data=[go.Bar(y=cv_scores, x=[f"Fold {i+1}" for i in range(len(cv_scores))], marker_color=selected_color)])
                fig.update_layout(title="äº¤å‰é©—è­‰å„æŠ˜å¾—åˆ†", xaxis_title="Fold", yaxis_title="å¾—åˆ†")
                st.plotly_chart(fig)
            else:
                st.write("æœªæ‰¾åˆ°äº¤å‰é©—è­‰çµæœã€‚")

        st.subheader("æœ€çµ‚æ¨¡å‹è©•ä¼°æŒ‡æ¨™")
        col1, col2, col3, col4 = st.columns(4)
        
        # ä½¿ç”¨ zero_division åƒæ•¸ä¾†é¿å…è­¦å‘Š
        accuracy = accuracy_score(st.session_state['y_test'], st.session_state['y_pred'])
        precision = precision_score(st.session_state['y_test'], st.session_state['y_pred'], zero_division=0)
        recall = recall_score(st.session_state['y_test'], st.session_state['y_pred'], zero_division=0)
        f1 = f1_score(st.session_state['y_test'], st.session_state['y_pred'], zero_division=0)
        
        col1.metric("æº–ç¢ºç‡", f"{accuracy:.4f}")
        col2.metric("ç²¾ç¢ºç‡", f"{precision:.4f}")
        col3.metric("å¬å›ç‡", f"{recall:.4f}")
        col4.metric("F1 åˆ†æ•¸", f"{f1:.4f}")

        # ROC curve and PR curve
        fpr, tpr, _ = roc_curve(st.session_state['y_test'], st.session_state['y_prob'])
        roc_auc = auc(fpr, tpr)
        precision, recall, _ = precision_recall_curve(st.session_state['y_test'], st.session_state['y_prob'])

        plotly_template = st.selectbox("é¸æ“‡ Plotly æ¨¡æ¿", ["plotly", "ggplot2", "seaborn", "simple_white", "plotly_white", "plotly_dark", "presentation", "xgridoff", "ygridoff", "gridon", "none"])

        col1, col2 = st.columns([1, 1], gap="small")

        with col1:
            fig_roc = go.Figure(data=go.Scatter(x=fpr, y=tpr, mode='lines', name='ROC curve'))
            fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)
            fig_roc.update_layout(
                title_text='ROC Curve',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                yaxis=dict(scaleanchor="x", scaleratio=1),
                xaxis=dict(constrain='domain'),
                height=500,
                template=plotly_template
            )
            fig_roc.add_annotation(
                x=0.5, y=0.5,
                text=f'AUC = {roc_auc:.4f}',
                showarrow=False,
                yshift=10
            )
            st.plotly_chart(fig_roc)

        with col2:
            fig_pr = go.Figure(data=go.Scatter(x=recall, y=precision, mode='lines', name='PR curve'))
            fig_pr.update_layout(
                title_text='Precision-Recall Curve',
                xaxis_title='Recall',
                yaxis_title='Precision',
                height=500,
                template=plotly_template
            )
            st.plotly_chart(fig_pr)

        # Confusion Matrix
        st.subheader("æ··æ·†çŸ©é™£")
        cm = confusion_matrix(st.session_state['y_test'], st.session_state['y_pred'])
        colorscale = st.selectbox("é¸æ“‡é¡è‰²æ¯”ä¾‹", ['aggrnyl', 'agsunset', 'algae', 'amp', 'armyrose', 'balance', 'blackbody', 'bluered', 'blues', 'blugrn', 'bluyl', 'brbg', 'brwnyl', 'bugn', 'bupu', 'burg', 'burgyl', 'cividis', 'curl', 'darkmint', 'deep', 'delta', 'dense', 'earth', 'edge', 'electric', 'emrld', 'fall', 'geyser', 'gnbu', 'gray', 'greens', 'greys', 'haline', 'hot', 'hsv', 'ice', 'icefire', 'inferno', 'jet', 'magenta', 'magma', 'matter', 'mint', 'mrybm', 'mygbm', 'oranges', 'orrd', 'oryel', 'oxy', 'peach', 'phase', 'picnic', 'pinkyl', 'piyg', 'plasma', 'plotly3', 'portland', 'prgn', 'pubu', 'pubugn', 'puor', 'purd', 'purp', 'purples', 'purpor', 'rainbow', 'rdbu', 'rdgy', 'rdpu', 'rdylbu', 'rdylgn', 'redor', 'reds', 'solar', 'spectral', 'speed', 'sunset', 'sunsetdark', 'teal', 'tealgrn', 'tealrose', 'tempo', 'temps', 'thermal', 'tropic', 'turbid', 'turbo', 'twilight', 'viridis', 'ylgn', 'ylgnbu', 'ylorbr', 'ylorrd'])
        
        fig = ff.create_annotated_heatmap(cm, x=['Predicted 0', 'Predicted 1'], y=['Actual 0', 'Actual 1'], colorscale=colorscale)
        fig.update_layout(title_text='Confusion Matrix', xaxis_title='Predicted label', yaxis_title='True label')
        st.plotly_chart(fig)

        # SHAP values
        st.subheader("æ¨¡å‹è§£é‡‹æ€§ (SHAP å€¼)")
        with st.spinner('è¨ˆç®— SHAP å€¼ä¸­...'):
            explainer = shap.TreeExplainer(st.session_state['model'])
            shap_values = explainer.shap_values(st.session_state['X_test_scaled'])
            
            # æª¢æŸ¥ shap_values çš„å½¢ç‹€
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
            elif len(shap_values.shape) == 3:
                shap_values = shap_values[:, :, 1]
            
            shap_df = pd.DataFrame(shap_values, columns=st.session_state['features'])
            shap_importance = shap_df.abs().mean().sort_values(ascending=False)
            
            colorscale = st.selectbox("é¸æ“‡é¡è‰²æ¯”ä¾‹", ['aggrnyl', 'agsunset', 'algae', 'amp', 'armyrose', 'balance', 'blackbody', 'bluered', 'blues', 'blugrn', 'bluyl', 'brbg', 'brwnyl', 'bugn', 'bupu', 'burg', 'burgyl', 'cividis', 'curl', 'darkmint', 'deep', 'delta', 'dense', 'earth', 'edge', 'electric', 'emrld', 'fall', 'geyser', 'gnbu', 'gray', 'greens', 'greys', 'haline', 'hot', 'hsv', 'ice', 'icefire', 'inferno', 'jet', 'magenta', 'magma', 'matter', 'mint', 'mrybm', 'mygbm', 'oranges', 'orrd', 'oryel', 'oxy', 'peach', 'phase', 'picnic', 'pinkyl', 'piyg', 'plasma', 'plotly3', 'portland', 'prgn', 'pubu', 'pubugn', 'puor', 'purd', 'purp', 'purples', 'purpor', 'rainbow', 'rdbu', 'rdgy', 'rdpu', 'rdylbu', 'rdylgn', 'redor', 'reds', 'solar', 'spectral', 'speed', 'sunset', 'sunsetdark', 'teal', 'tealgrn', 'tealrose', 'tempo', 'temps', 'thermal', 'tropic', 'turbid', 'turbo', 'twilight', 'viridis', 'ylgn', 'ylgnbu', 'ylorbr', 'ylorrd'],key="shap_importance")

            fig = go.Figure(go.Bar(
                y=shap_importance.index,
                x=shap_importance.values,
                orientation='h',
                marker=dict(
                    color=shap_importance.values,
                    colorscale=colorscale,
                    colorbar=dict(title="SHAP å€¼")
                )
            ))
            
            fig.update_layout(
                title='ç‰¹å¾µé‡è¦æ€§ (åŸºæ–¼ SHAP å€¼)',
                xaxis_title='å¹³å‡ |SHAP å€¼|',
                yaxis_title='ç‰¹å¾µ',
                height=500,
                width=700
            )
            
            st.plotly_chart(fig)
            st.markdown("""
            #### SHAPå€¼è§£é‡‹

            ##### ä»€éº¼æ˜¯SHAPå€¼ï¼Ÿ

            SHAPå€¼ï¼ˆSHapley Additive exPlanationsï¼‰å¹«åŠ©æˆ‘å€‘ç†è§£æ¯å€‹ç‰¹å¾µå¦‚ä½•å½±éŸ¿æ¨¡å‹çš„é æ¸¬çµæœã€‚æƒ³åƒä¸€ä¸‹,æ¯å€‹ç‰¹å¾µéƒ½æ˜¯ä¸€å€‹çƒå“¡,è€ŒSHAPå€¼å°±æ˜¯è©•åˆ†å¡,å‘Šè¨´æˆ‘å€‘æ¯å€‹çƒå“¡å°æ¯”è³½çµæœçš„è²¢ç»ã€‚

            ##### SHAPå€¼çš„å«ç¾©

            - **æ­£å€¼**ï¼šé€™å€‹ç‰¹å¾µå¢åŠ äº†å®¢æˆ¶å¯èƒ½æµå¤±çš„æ©Ÿæœƒã€‚
            ä¾‹å¦‚ï¼šå¦‚æœ"å®¢æˆ¶æœå‹™æ»¿æ„åº¦"çš„SHAPå€¼ç‚ºæ­£,æ„å‘³è‘—è¼ƒä½çš„æ»¿æ„åº¦å¢åŠ äº†å®¢æˆ¶æµå¤±çš„å¯èƒ½æ€§ã€‚

            - **è² å€¼**ï¼šé€™å€‹ç‰¹å¾µæ¸›å°‘äº†å®¢æˆ¶å¯èƒ½æµå¤±çš„æ©Ÿæœƒã€‚
            ä¾‹å¦‚ï¼šå¦‚æœ"ä½¿ç”¨æ™‚é•·"çš„SHAPå€¼ç‚ºè² ,æ„å‘³è‘—ä½¿ç”¨æ™‚é–“è¶Šé•·,å®¢æˆ¶è¶Šä¸å¯èƒ½æµå¤±ã€‚
                        
            ##### SHAPå€¼çµ±è¨ˆä¿¡æ¯

            ä»¥ä¸‹æ˜¯SHAPå€¼çš„çµ±è¨ˆä¿¡æ¯,å¹«åŠ©æˆ‘å€‘äº†è§£æ¯å€‹ç‰¹å¾µå½±éŸ¿çš„ç¯„åœå’Œæ•´é«”è¶¨å‹¢ï¼š
            """)

            st.write(shap_df.describe())

            st.markdown("""
            - **å¹³å‡å€¼**ï¼šç‰¹å¾µé€šå¸¸çš„å½±éŸ¿ç¨‹åº¦
            - **æœ€å°å€¼å’Œæœ€å¤§å€¼**ï¼šç‰¹å¾µå½±éŸ¿çš„æ¥µç«¯æƒ…æ³
            - **25%ã€50%ã€75%åˆ†ä½æ•¸**ï¼šç‰¹å¾µå½±éŸ¿çš„å¸¸è¦‹ç¯„åœ
            """)
        
        if hasattr(st.session_state['model'], 'feature_importances_'):
            st.subheader("ç‰¹å¾µé‡è¦æ€§")
            feature_importance = pd.DataFrame({
                'feature': st.session_state['features'],
                'importance': st.session_state['model'].feature_importances_
            }).sort_values('importance', ascending=False)
            
            chart_type = st.selectbox("é¸æ“‡åœ–è¡¨é¡å‹", ['Horizontal Bar', 'Vertical Bar'], key="feature_importance_chart_type")
            colorscale = st.selectbox("é¸æ“‡é¡è‰²æ¯”ä¾‹", ['aggrnyl', 'agsunset', 'algae', 'amp', 'armyrose', 'balance', 'blackbody', 'bluered', 'blues', 'blugrn', 'bluyl', 'brbg', 'brwnyl', 'bugn', 'bupu', 'burg', 'burgyl', 'cividis', 'curl', 'darkmint', 'deep', 'delta', 'dense', 'earth', 'edge', 'electric', 'emrld', 'fall', 'geyser', 'gnbu', 'gray', 'greens', 'greys', 'haline', 'hot', 'hsv', 'ice', 'icefire', 'inferno', 'jet', 'magenta', 'magma', 'matter', 'mint', 'mrybm', 'mygbm', 'oranges', 'orrd', 'oryel', 'oxy', 'peach', 'phase', 'picnic', 'pinkyl', 'piyg', 'plasma', 'plotly3', 'portland', 'prgn', 'pubu', 'pubugn', 'puor', 'purd', 'purp', 'purples', 'purpor', 'rainbow', 'rdbu', 'rdgy', 'rdpu', 'rdylbu', 'rdylgn', 'redor', 'reds', 'solar', 'spectral', 'speed', 'sunset', 'sunsetdark', 'teal', 'tealgrn', 'tealrose', 'tempo', 'temps', 'thermal', 'tropic', 'turbid', 'turbo', 'twilight', 'viridis', 'ylgn', 'ylgnbu', 'ylorbr', 'ylorrd'], key="feature_importance_colorscale")

            if chart_type == 'Horizontal Bar':
                fig = go.Figure(go.Bar(
                    y=feature_importance['feature'],
                    x=feature_importance['importance'],
                    orientation='h',
                    marker=dict(
                        color=feature_importance['importance'],
                        colorscale=colorscale,
                        colorbar=dict(title="é‡è¦æ€§")
                    )
                ))
            elif chart_type == 'Vertical Bar':
                fig = go.Figure(go.Bar(
                    x=feature_importance['feature'],
                    y=feature_importance['importance'],
                    orientation='v',
                    marker=dict(
                        color=feature_importance['importance'],
                        colorscale=colorscale,
                        colorbar=dict(title="é‡è¦æ€§")
                    )
                ))

            fig.update_layout(
                title='ç‰¹å¾µé‡è¦æ€§',
                xaxis_title='é‡è¦æ€§' if chart_type == 'Vertical Bar' else 'ç‰¹å¾µ',
                yaxis_title='ç‰¹å¾µ' if chart_type == 'Vertical Bar' else 'é‡è¦æ€§',
                height=500,
                width=700
            )

            st.plotly_chart(fig)

    else:
        st.warning("Please train the model first! @data_lemak")

    # Model Deployment Simulation
    st.header("8. Model Deployment Simulation")
    st.write("è¼¸å…¥æ–°çš„æ•¸æ“šï¼Œçœ‹çœ‹æ¨¡å‹çš„é æ¸¬çµæœï¼š")

    if 'features' in st.session_state:
        input_data = {}
        for feature in st.session_state['features']:
            if st.session_state.df[feature].dtype == 'object':
                input_data[feature] = st.selectbox(f"Select {feature}", st.session_state.df[feature].unique())
            else:
                input_data[feature] = st.number_input(f"Enter {feature}", value=float(st.session_state.df[feature].mean()))

        if 'prediction_value' not in st.session_state:
            st.session_state['prediction_value'] = None

        if st.button("é æ¸¬"):
            if 'model' in st.session_state:
                input_df = pd.DataFrame([input_data])
                input_scaled = st.session_state['scaler'].transform(input_df)
                prediction = st.session_state['model'].predict_proba(input_scaled)[0]
                st.session_state['prediction_value'] = f"{prediction[1]:.2%}"
            else:
                st.warning("è«‹å…ˆè¨“ç·´æ¨¡å‹ï¼")

        if st.session_state['prediction_value'] is not None:
            st.metric(label="å®¢æˆ¶æµå¤±çš„æ©Ÿç‡", value=st.session_state['prediction_value'])
    else:
        st.warning("Please train the model first! @data_lemak")

    # What-If Analysis
    st.header("9. What-If Analysis")
    st.write("èª¿æ•´ç‰¹å¾µå€¼ï¼Œçœ‹çœ‹å¦‚ä½•å½±éŸ¿æ¨¡å‹çš„é æ¸¬ï¼š")

    if 'features' in st.session_state:
        feature_to_change = st.selectbox("é¸æ“‡è¦èª¿æ•´çš„ç‰¹å¾µ", st.session_state['features'])
        if feature_to_change in input_data:
            original_value = input_data[feature_to_change]
            new_value = st.slider(f"èª¿æ•´ {feature_to_change} çš„å€¼", 
                                float(st.session_state.df[feature_to_change].min()), 
                                float(st.session_state.df[feature_to_change].max()), 
                                float(original_value))

            if 'original_prediction' not in st.session_state:
                st.session_state['original_prediction'] = None
            if 'new_prediction' not in st.session_state:
                st.session_state['new_prediction'] = None
            if 'change' not in st.session_state:
                st.session_state['change'] = None

            if st.button("æ¯”è¼ƒé æ¸¬çµæœ"):
                if 'model' in st.session_state:
                    original_input = pd.DataFrame([input_data])
                    original_scaled = st.session_state['scaler'].transform(original_input)
                    st.session_state['original_prediction'] = st.session_state['model'].predict_proba(original_scaled)[0][1]
                    
                    new_input = original_input.copy()
                    new_input[feature_to_change] = new_value
                    new_scaled = st.session_state['scaler'].transform(new_input)
                    st.session_state['new_prediction'] = st.session_state['model'].predict_proba(new_scaled)[0][1]
                    
                    st.session_state['change'] = float(st.session_state['new_prediction'] - st.session_state['original_prediction'])
                    
            if st.session_state['original_prediction'] is not None and st.session_state['new_prediction'] is not None:
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(label="åŸå§‹é æ¸¬", value=f"{float(st.session_state['original_prediction']):.2%}")
                with col2:
                    st.metric(label="æ–°é æ¸¬", value=f"{float(st.session_state['new_prediction']):.2%}")
                with col3:
                    if st.session_state['change'] > 0:
                        st.metric(label="è®ŠåŒ–", value=f"{st.session_state['change']:.2%}", delta=f"{st.session_state['change']:.2%}", delta_color="inverse")
                    else:
                        st.metric(label="è®ŠåŒ–", value=f"{st.session_state['change']:.2%}", delta=f"{st.session_state['change']:.2%}", delta_color="normal")
    else:
        st.warning("Please train the model first! @data_lemak")